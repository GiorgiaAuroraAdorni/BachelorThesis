\chapter{Esperimenti e risultati}
\label{chap:esperimenti}

I precedenti modelli di previsione della personalità si sono concentrati sull'applicazione di tecniche generali di apprendimento automatico per predire i tratti di personalità Big Five.
In particolare verranno utilizzate diverse strutture di rete, combinando differenti domini.

\section{Spazi di rappresentazione}
\label{sec:approcci}
Per affrontare questo problema di \emph{Text Mining}, gli esperimenti si concentrano su due principali metodi per l'estrazione delle caratteristiche:
\begin{itemize}
	\item Un approccio supervisionato, in cui viene utilizzato come strumento di generazione di feature un vettore \emph{bag-of-words} o brevemente BoW, una rappresentazione di testo che descrive la presenza delle parole all'interno di un documento, in questo caso nel dizionario delle occorrenze.
	\item Un approccio non supervisionato, in cui viene costruito un embedding, tramite gli algoritmi di Mikolov. Insegnando alla rete il significato delle parole e la relazione tra di esse, è possibile rappresentare, sotto forma di vettori, le mappature tra le parole e i contesti.
\end{itemize}
$\\$
In seguito viene posta l'attenzione su tre diverse architetture neurali:
\begin{itemize}
	\item Reti fully-connected;
	\item Reti neurali convoluzionali CNN;
	\item Classificatori multi-label binari.
\end{itemize}



\section{Esperimento 1}
\label{sec:es1}
\subsection{Input Features}
\label{subsec:features1}

Nel primo approccio proposto, per rappresentare i dati testuali viene utilizzato il modello \emph{bag-of-words}, un tipo di descrizione semplificata, spesso utilizzata nell'elaborazione del linguaggio naturale e nel campo dell'\emph{Information Retrivial} (IR). 

Sfruttando il dizionario delle occorrenze precedentemente costruito, il testo viene modellato  come fosse una ``borsa di parole'', in cui grammatica e ordine delle parole vengono trascurate.
Ogni frase viene ridotta ad un vettore in cui ogni elemento identifica una parola del dizionario. Nella posizione corrispondente ad un determinato termine vi sarà il valore \num{1} se la parola è contenuta nella frase, \num{0} altrimenti.

Il modello riguarda solo le parole conosciute, di conseguenza i vocaboli che compaiono nel testo ma sono assenti nel dizionario vengono trascurati.

\begin{figure}[H]
	\centering
	{\includegraphics[width=.6\textwidth]{images/bow}}
	\caption{Visualizzazione del modello \emph{bag-of-words}}
	\label{fig:bow}
\end{figure}

\subsection{Architettura della rete}
\label{subsec:modelli1}

Una volta estratte, le features posso essere passate in input alla rete neurale, che le elabora calcolando le risposte dei neuroni dal livello di input verso il livello di output.

In questa prima strategia viene utilizzata una rete \emph{feedforward}, in cui le informazioni si spostano dal livello di input attraverso eventuali strati nascosti fino al livello di output senza cicli. L'architettura è caratterizzata da una struttura densa o \emph{fully-connected}, in cui tutti i neuroni del layer precedente sono collegati ad ogni neurone del layer successivo, e ciascuna connessione ha il proprio peso.


Lo scopo di un layer completamente connesso è imparare combinazioni non lineari di feature ad alto livello provenienti dal layer precedente. L'ultimo di questi strati rappresenta l’output della rete.

Ad ogni livello fully connected viene applicata la funzione di attivazione non lineare \emph{ReLU}, descritta nella sezione \ref{subsec:fattivazione}.

Inoltre, per accelerare l'apprendimento ed aumentare la stabilità della rete, effettuiamo dopo ogni layer una \emph{batch normalization}, definita nella sezione \ref{subsec:normalization}. {\color{red}in realtà non mi pare si sia descritto come funziona in quella sezione, decida come desidera trattare questi aspetti per evitare che le vengano mosse obiezioni}

Vengono presentate nella tabella \ref{tab:arcbow+fc} tre architetture implementate, con differenti strati e numero di neuroni che caratterizza ciascuno.


\begin{figure}[H]
	\centering
		\begin{tabular}{lcccc}
			\toprule
			\textbf{Layer} \quad & \textbf{Modello 1} & \textbf{Modello 2} & \textbf{Modello 3} &  \textbf{Modello 4}  \\
			\midrule
			Input 				 & \numprint{60000}	  & \numprint{60000}   &\numprint{60000}	&\numprint{60000}	   \\
			fc1  				 & \num{300}		  & \num{300} 		   & \num{100} 			& \num{300} 		   \\
			fc2  				 &  \num{200}		  & \num{200} 		   & \num{50}  			& \num{20}  		   \\
			fc3					 & -				  & \num{100} 		   & \num{20} 			& -					   \\
			Output 				 &  \num{5}			  & \num{5} 		   & \num{5}			& \num{5} 			   \\
			\bottomrule
		\end{tabular}
	\captionof{table}{Confronto delle architetture di tre differenti modelli}
	\label{tab:arcbow+fc}
\end{figure}

Tutte le simulazioni sono state addestrate per \num{10} epoche: la fase di addestramento viene in genere portata avanti fino a quando le performance sul test non producono alcun miglioramento.

L’ottimizzatore scelto è l'{Adaptive Subgradient Methods} \emph{Adagrad}, introdotto nella sezione \ref{subsubsec:adagrad}, con learning rate \numprint{0,001}.

Come funzione di loss è stato scelto l'errore quadratico medio, in inglese \emph{mean squared error (MSE)}, presentato nella sezione \ref{subsec:loss}. Mentre la metrica di valutazione utilizzata per misurare le prestazioni predittive del modello è la \emph{root mean squared error} (RMSE), introdotta nella sezione \ref{subsec:EvaluationMetric}.

In ogni epoca si alternano una fase di training ed una fase di test in modo tale da monitorare costantemente i miglioramenti o i peggioramenti del modello sul test set. 

\subsection{Performance}
\label{subsec:performance1}
Prendendo in considerazione le tre diverse architetture implementate, presentiamo i risultati ottenuti in termini di loss.
\begin{table}[H]
	\centering
	\begin{tabular}{l@{\hspace{.5cm}}ccc}
		\toprule
		 & \textbf{Dev loss} & \textbf{Test loss} & \textbf{Tempo di training}  \\
		\midrule
		\textbf{Modello 1} & \numprint{0.0607} & \numprint{0.0619} &\numprint{235} min \\
		\textbf{Modello 2} & \numprint{0.0901} & \numprint{0.0606} &\numprint{250} min \\
		\textbf{Modello 3} & \numprint{0.0680} & \numprint{0.0624} &\numprint{265} min \\
%		\textbf{Modello 4} & \numprint{0.0287} & \numprint{0.0104} &\numprint{145} min \\
		\bottomrule 
	\end{tabular}
	\captionof{table}{Confronto dei risultati in termini di \emph{loss} ottenuti dalle tre diverse reti}
	\label{tab:lossbow+fc}
\end{table}

Per valutare l'efficacia di questi modelli, è fondamentale eseguire un analisi dettagliata, in particolare ponendo l'attenzione sui valori di RMSE per ogni tratto di personalità.
Calcolando il valore medio assunto da ogni caratteristica durante la fase di addestramento, è possibile stabilire qual è il valore di root mean squared error di un modello concettuale che per ogni tratto predice sempre il suo valore medio.
 
\begin{figure}[H]
	\centering
	\begin{tabular}{clccccc}
		\toprule	
		& 		  & \multicolumn{5}{c}{\textbf{Root Mean Squared Error}} 									    \\
		\multicolumn{2}{c}{\multirow{-2}{*}{Modelli}}
		& O 				& C 			   & E 				  & A 				 & N 			    \\ 
		\midrule
		\multirow{2}*{\textbf{Modello 1}} & Modello   & \numprint{0,148} & \numprint{0,227} & \numprint{0,224} & \numprint{0,251} & \numprint{0,351} \\
		& Modello 0 & \numprint{0,145} & \numprint{0,224} & \numprint{0,213} & \numprint{0,218} & \numprint{0,318} \\
		\midrule
		\multirow{2}*{\textbf{Modello 2}} & Modello   & \numprint{0,147} & \numprint{0,226} & \numprint{0,225} & \numprint{0,251} & \numprint{0,341} \\
		& Modello 0 & \numprint{0,141} & \numprint{0,227} & \numprint{0,213} & \numprint{0,208} & \numprint{0,305} \\
		\midrule
		\multirow{2}*{\textbf{Modello 3}} & Modello   & \numprint{0,147} & \numprint{0,226} & \numprint{0,225} & \numprint{0,262} & \numprint{0,348} \\
		& Modello 0 & \numprint{0,233} & \numprint{0,307} & \numprint{0,262} & \numprint{0,373} & \numprint{0,546}  \\
%		\midrule
%		\multirow{2}*{\textbf{Modello 4}} & Modello   & \numprint{0,147} & \numprint{0,22 s6} & \numprint{0,225} & \numprint{0,262} & \numprint{0,348} \\
%		& Modello 0 & \numprint{0,233} & \numprint{0,307} & \numprint{0,262} & \numprint{0,373} & \numprint{0,546}  \\
		\bottomrule	
	\end{tabular}
	\captionof{table}{Confronto dei risultati in termini di \emph{Root Mean Squared Error} delle architetture contro il modello basato sulla media di training}
	\label{tab:confmm0bow+fc}
\end{figure}

\begin{figure}[htb]
	\centering
	{\includegraphics[width=.75\textwidth]{images/loss1}} 
	\caption{Visualizzazione delle training loss dei tre modelli}
	\label{fig:loss}
\end{figure}


Mettendo a confronto le due metriche, si nota che i modelli realmente implementati imparano nella maggioranza dei casi a predire un valore con lo stesso errore commesso dai modelli banali che calcolano la media. Risulta allora evidente che i risultati ottenuti non siano ottimali.

{\color{red} Nonostante ciò, il terzo modello sembrerebbe essere meglio.

In seguito a questa analisi, il termo modello sembrerebbe essere leggermente migliore degli altri due. 
Dall'analisi seguita al confronto del modello ocn il suo modello 0, esso è quello che ottiene risultati migliori rispetto ad esso, quindi la rete sembrerebbe effettivamente imparare qualcosa di più. SI può migliorare. come?}

La scarsa efficienza di questi modelli potrebbe dipendere dall'efficacia con cui vengono codificate le feature in input alla rete. 
Infatti le limitazioni dell'approccio bag-of-words derivano in parte dalla progettazione del vocabolario e della sua dimensione, che può causare una scarsa ``descrizione'' del documento. 
Scartare l'ordine delle parole e ignorare il contesto non consente di determinare la differenza tra le stesse parole disposte diversamente, i sinonimi ecc.
Inoltre, un tipo di rappresentazione sparsa risulta più difficile da modellare quando si cercano modelli in grado di sfruttare poche informazioni in uno spazio rappresentativo ampio, sia per ragioni computazionali (spazio e complessità temporale) sia per ragioni di informazione.

\section{Esperimento 2}
\label{sec:es2}

In compiti come il riconoscimento di parole, tutte le ``informazioni'' vengono rappresentati per mezzo di id unici e discreti.
Queste codifiche però non forniscono alcuna informazione utile al sistema riguardo le relazioni che possono sussistere tra i singoli elementi. Ciò significa che quando sta elaborando i dati, il modello può sfruttare molto poco di ciò che ha appreso su una determinato termine. 

La ``raffigurazione'' utilizzata nel precedente approccio, ha portato alla creazione di dati sparsi. Di conseguenza, per ottenere un modello di successo, un alternativa valida sarebbe quella di sfruttare \emph{modelli spaziali vettoriali} (VSM) per rappresentare le parole in uno spazio continuo \cite{FIXME}.
Questi metodi dipendono dall'ipotesi distributiva, la quale afferma che le parole che appaiono negli stessi contesti condividono lo stesso significato semantico \cite{FIXME}. 

\subsection{Input Features}
\label{subsec:features2}

Nel secondo approccio, viene utilizzato un modello spazio-vettoriale, adottando una tecnica non supervisionata che consiste nell'applicazione di \texttt{word2vec} di Tomas Mikolov \cite{mikolov2013efficient}. 
\texttt{Word2vec} è un modello predittivo particolarmente efficiente dal punto di vista computazionale per l'apprendimento degli embedding di parole dal testo non elaborato.
{\color{blue}Esso viene implementato come una} rete neurale a due strati, addestrati a ricostruire i contesti linguistici delle parole.

A partire dal corpus di testo, l'algoritmo prende in input un set formato dall'accoppiamento di ogni parola target e i contesti in cui appare. Viene considerato come ``contesto'' l'insieme delle ``parole a sinistra'' e delle ``parole alla destra'' dell'obiettivo, ovvero la finestra di dimensione 1 attorno all'elemento target. Ogni coppia di destinazione del contesto viene trattata come se fosse una nuova osservazione, incrementando le informazioni distribuzionali. Viene così prodotto uno spazio vettoriale di diverse centinaia di dimensioni, in cui ogni parola univoca viene assegnata a un vettore corrispondente nello spazio.


Per l'implementazione viene utilizzato il modello \emph{Skip-Gram}, una versione di \texttt{word2vec} che vuole predire le parole del contesto di origine (label) a partire dalle parole target (features) \cite{FIXME}.

\begin{figure}[H]
	\centering
	{\includegraphics[width=.7\textwidth]{images/skip-gram}} 
	\caption{Visualizzazione del modello Skip-gram}
	\label{fig:mikolov}
\end{figure}

In questo tipo di apprendimento, i vettori si posizionano nello spazio in modo tale che le parole che condividono contesti comuni nel corpo siano situate in stretta prossimità l'una dell'altra. Un esempio interessante viene illustrato nella figura \ref{fig:embedding1}\subref{subfig:vis3d} --- si ponga particolare attenzione alle parole ``beautiful'', ``lovely'', ``chic'', ``trendy'' ecc.. --- in cui i vocaboli semanticamente simili si trovano vicini dello spazio.

\begin{figure}[H]
	\centering
	\subfloat[][\emph{Visualizzazione 2D}\label{subfig:vis2d}]
	{\includegraphics[width=.4\textwidth]{images/embedding1/embedding1_tsne_2d}}
	\hspace{10mm}
	\subfloat[][\emph{Dettaglio di una visualizzazione 3D}\label{subfig:vis3d}]
	{\includegraphics[width=.45\textwidth]{images/embedding1/Embedding1_similarity}}
	
	\caption{Proiezione dell'embedding di Mikolov nello spazio 2-3 dimensionale, tramite la \emph{tecnica di riduzione della dimensionalità} (t-SNE) \cite{FIXME}.}
	\label{fig:embedding1}
\end{figure}

{\color{red}La funzione obiettivo/algoritmo di ottimizzazione della rete utilizzata per la costruzione dell'embedding viene definita sull'intero set di dati, ed ottimizzata con la \emph{Socastic Gradient Descent} (SGD) un esempio alla volta \cite{FIXME} \ref{subsec:optimizer}.
loss function: nce loss. learning rate
}

Nella seguente tabella vengono presentati i due embedding realizzati e i relativi parametri.

\begin{figure}[htb]
	\centering
	\begin{tabular}{ccc}
		\toprule	
		 		  				& \multicolumn{2}{c}{\textbf{Parameters}}	\\
		{\multirow{-2}{*}{Embedding}}
								& Embedding Size 	& Num Sampled 	 		\\ 
		\midrule
		\textbf{Embedding 1}    & \numprint{40} 	& \numprint{20}  		\\
		\midrule
		\textbf{Embedding 2}    & \numprint{250} 	& \numprint{50}  		\\
		\bottomrule	
	\end{tabular}
	\captionof{table}{Confronto dei parametri della rete impostati per la realizzazione dell'embedding}
	\label{tab:confemb}
\end{figure}

\subsection{Architettura della rete}
\label{subsec:modelli2}
%Windowing, parole attorno agli aggettivi della lista degli aggettivi disponibili:
%K parole prima e dopo la parola corrente, finestre scorrevoli

La rappresentazione spazio-vettoriale viene utilizzata come feature della rete che si andrà a costruire.
{\color{red}Un modo alternativo per addestrare il modello consiste nell'utilizzare le \emph{reti convoluzionali}, in cui ogni neurone è collegato solo a pochi neuroni vicini (alias locali) nel livello precedente, e lo stesso insieme di pesi viene utilizzato per ogni neurone. Uno strato convoluzionale è molto più specializzato ed efficiente di uno completamente connesso

In una rete convoluzionale, il modello di connessione locale e lo schema di peso condiviso possono essere interpretati come un filtro (o un insieme di filtri) che viene "convogliato" con l'input.
Esso è costituito da un insieme di ``filtri'' che accettano un sottoinsieme dei dati di input alla volta, ma vengono applicati all'intero input.}

Le operazioni eseguite da questi strati vengono trasformate in ``moltiplicazioni'' non lineari tramite l'applicazione della funzione di attivazione \emph{ReLU}, introdotta nella sezione \ref{subsec:fattivazione}.

Ad ogni livello convoluzionale viene applicata una \emph{batch normalization}, definita nella sezione \ref{subsec:normalization}, {\color{blue} utilizzata sull'input per il ridimensionamento delle funzionalità e la normalizzazione batch nei livelli nascosti.}

{\color{red} Dopo il primo strato convoluzionale viene inserito un \emph{layer di pooling} \cite{FIXME} \ref{FIXME} \ref{sec:cnn}: Un livello di raggruppamento riduce in modo efficace i campioni dell'output del livello precedente, riducendo il numero di operazioni richieste per tutti i livelli successivi, ma passando comunque le informazioni valide dal livello precedente.

Come ultimo strato della rete viene scelto un \emph{layer denso}, un'operazione lineare sul vettore di input del livello che esegue una serie di trasformazioni sulla rappresentazione profonda e alla fine emette i punteggi per ogni classe.}\\


\begin{figure}[H]
	\centering
	\begin{tabular}{lccc}
		\toprule
		\textbf{Layer}& \textbf{Modello 4} & \textbf{Modello 5} & \textbf{Modello 6} 		\\ 
		\midrule
		conv1 	& \num{10}$\times$\num{5}, 10	  & \num{5}$\times$\num{5}, 150, padding same    &\num{3}$\times$\num{3}, 100, padding same 		   \\
		
		mpool1 	& &{\num{4}$\times$\num{4}, stride 2, padding same}	&   \\
		conv2  	& \num{18}$\times$\num{18}, 10	  &  \num{5}$\times$\num{20}, 100, padding same	  &		\num{3}$\times$\num{20}, 75, padding same    \\
		conv3  	& ---	  & \num{1}$\times$\num{20}, 50, 	   &	\num{1}$\times$\num{20}, 50 	   \\
		fcout		& &{\num{1}$\times$\num{1}, 5}&		   \\
		
		\bottomrule	
	\end{tabular}
	\captionof{table}{Architetture implementate a partire dall'embedding 1}
	\label{tab:netemb1}
\end{figure}

Vengono presentate nelle tabelle \ref{tab:netemb1} e \ref{tab:netemb2} le diverse configurazioni dei layer convoluzionali delle architetture implementate per i due embedding.

{\color{red}L'input è costituito da un numero di caratteristiche pari a \num{40}$\times$``numero delle parole'' di ogni sentence.}

Nel caso del secondo embedding abbiamo voluto provare un modello che sfruttasse solo le reti fully connected, senza alcun layer di convoluzione. 

\begin{figure}[H]
	\centering
	\begin{tabular}{lcc}
		\toprule
		\textbf{Layer}& \textbf{Modello 7} 								  & \textbf{Modello 8} 			   \\ 
		\midrule
		conv1 	& \num{3}$\times$\num{3}, 100, stride 2, padding same     & ---	   \\
		mpool1 	& \num{4}$\times$\num{4}, stride 2, padding same		  & ---	   \\
		conv2  	& \num{3}$\times$\num{63}, 75, stride 2, padding same	  & ---    \\
		conv3  	& \num{1}$\times$\num{32}, 50, stride 2	  				  & ---	   \\
		fc1  	& ---													  & \num{1}$\times$\num{1}, 100	   \\
		fc2  	& \num{1}$\times$\num{32}, 50, stride 2	  				  & \num{1}$\times$\num{1},  50    \\
		fc3  	& \num{1}$\times$\num{32}, 50, stride 2	  				  & \num{1}$\times$\num{1},  20	   \\
		fcout	& \num{1}$\times$\num{1}, 5   			  				  & \num{1}$\times$\num{1},   5	   \\
		\bottomrule	
	\end{tabular}
	\captionof{table}{Architetture implementate a partire dall'embedding 2}
	\label{tab:netemb2}
\end{figure}

\subsection{Performance}
\label{subsec:performance2}

Prendendo in considerazione i due diversi embedding, mettiamo a confronto le diverse architetture implementate, mostrando i risultati ottenuti in termini di loss.
\begin{table}[H]
	\centering
	\begin{tabular}{l@{\hspace{.5cm}}ccc}
		\toprule
		 & \textbf{Dev loss} & \textbf{Test loss} & \textbf{Tempo di training}  \\
		\midrule
		\textbf{Modello 4} & \numprint{0.061} & \numprint{0.058} &\numprint{200} min \\
		\textbf{Modello 5} & \numprint{0.052} & \numprint{0.060} &\numprint{310} min \\
		\textbf{Modello 6} & \numprint{0.042} & \numprint{0.060} &\numprint{540} min \\
		\midrule
		\textbf{Modello 7} & \numprint{0.038} & \numprint{0.057} &\numprint{225} min \\
		\textbf{Modello 8} & \numprint{0.058} & \numprint{0.117} &\numprint{250} min \\	
		\bottomrule 
	\end{tabular}
	\captionof{table}{Confronto dei risultati in termini di \emph{loss} ottenuti nelle diverse reti con i due diversi embedding}
	\label{tab:lossmikolov}
\end{table}

Nella seguente tabella vengono riassunti i valori di RMSE per ogni tratto di personalità.

\begin{figure}[H]
	\centering
	\begin{tabular}{clccccc}
		\toprule	
		& 		 			& \multicolumn{5}{c}{\textbf{Root Mean Squared Error}} 									       \\
		\multicolumn{2}{c}{\multirow{-2}{*}{Modelli}}
							& O 				& C 			   & E 				  & A 				 & N 			   \\ 
		\midrule
		\multirow{3}*{\textbf{Embedding 1}} 
				& Modello 4 & \numprint{0,1482} & \numprint{0,2256} & \numprint{0,2316} & \numprint{0,2524} & \numprint{0,3132} \\
				& Modello 5 & \numprint{0,1464} & \numprint{0,2269} & \numprint{0,2303} & \numprint{0,2514} & \numprint{0,3359} \\
				& Modello 6 & \numprint{0,1464} & \numprint{0,2246} & \numprint{0,2237} & \numprint{0,2514} & \numprint{0,3370} \\
		\midrule
		\multirow{2}*{\textbf{Embedding 2}} 
				& Modello 7 & \numprint{0,1465} & \numprint{0,2231} & \numprint{0,2223} & \numprint{0,2511} & \numprint{0,3204} \\
				& Modello 8 & \numprint{0,3993} & \numprint{0,2749} & \numprint{0,2574} & \numprint{0,2708} & \numprint{0,4567} \\
		\bottomrule	
	\end{tabular}
	\captionof{table}{Confronto dei risultati in termini di \emph{Root Mean Squared Error} delle architetture sul test set}
	\label{tab:rmsemikolov}
\end{figure}

\begin{figure}[H]
	\centering
	{\includegraphics[width=.75\textwidth]{images/rmse2-linlong}} 
	\caption{Visualizzazione delle training RMSE dei modelli}
	\label{fig:rmse}
\end{figure}


% può aiutare a superare alcuni dei sopracitati ostacoli.

\section{Risultati}
\label{sec:risultati}



%Vi sono stati numerosi esperimenti prima di ottenere il modello finale, ovvero quello con le performance migliori. Di seguito vengono descritti brevemente soltanto quelli più significativi, mentre per la descrizione precisa del modello finale si rimanda alla sezione successiva.\\



%Abbiamo valutato il nostro approccio basato sulla conoscenza sulla sua efficacia nel predire la personalità degli individui rispetto al modello dei Big Five. La nostra valutazione misura le prestazioni di: 1) classificare gli individui per ogni tratto di personalità e 2) stimare il grado di appartenenza degli individui a ciascun tratto di personalità. La prima valutazione è definita come un problema di classificazione multi-etichetta e assegna etichette "Sì" e "No" per gli individui per ciascun tratto di personalità. Questa è la metodologia di valutazione più popolare seguita nella letteratura sulla previsione della personalità. La seconda valutazione si concentra sul grado di appartenenza di ciascun individuo a ciascun tratto di personalità rispetto all'assegnazione di etichette piuttosto rigide "Sì" e "No". Gran parte della ricerca pertinente in letteratura non ha valutato questa impostazione della previsione della personalità [19]. Riteniamo che questa impostazione sia più vicina allo scenario del mondo reale dal momento che ogni individuo ha alcune caratteristiche da ogni tratto della personalità piuttosto che appartenere a ciascun tratto o meno. La seconda valutazione è definita come un problema di regressione e usiamo la regressione lineare e SVM per la regressione [9] per stimare il valore del grado di appartenenza.
%
%Dataset di valutazione
%Abbiamo utilizzato il famoso repository di dati di Facebook gestito dal progetto "myPersonality" 3 come set di dati di valutazione nei nostri esperimenti. Questo repository viene creato raccogliendo i dati utilizzando la popolare applicazione Facebook "myPersonality" lanciata nel 2007. I valori di personalità degli individui nel set di dati vengono valutati chiedendo loro di fare un test psicometrico standard. L'output di questo test mostra il grado di appartenenza di ciascun individuo a ciascun tratto di personalità e questi valori sono compresi tra 1 e 5. Ad esempio, un individuo può avere valori 2,85 per extraversione, 4,20 per nevroticismo, 2,12 per coscienziosità, 3,55 per gradevolezza e 4.31 per i tratti di personalità di apertura. Attualmente, possiede i dati di milioni di utenti di Facebook e contiene i loro aggiornamenti di stato, rete di amici, Mi piace ecc.
%Il nostro approccio sfrutta la semantica degli aggiornamenti di stato degli utenti. Il numero di aggiornamenti di stato di Facebook da parte degli utenti mostra una distribuzione a coda lunga come mostrato nella Figura 3. Abbiamo creato un set di dati di esempio da questo set di dati di grandi dimensioni come dataset di valutazione in base al numero di aggiornamenti di stato degli utenti. Abbiamo selezionato 1.000 utenti con il più alto numero di aggiornamenti di stato poiché si è osservato che un minor numero di aggiornamenti di stato non fornisce informazioni limitate o limitate [20]. Il numero di aggiornamenti di stato per gli utenti selezionati è riportato nella Figura 4. L'utente con gli aggiornamenti di stato massimi ha avuto 2.450 aggiornamenti, mentre l'utente con aggiornamenti di stato minimi ha 702 aggiornamenti di stato.
%


%\subsection{Layer di pooling}
%\label{subsec:layermp}
%
